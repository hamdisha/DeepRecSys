{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Recommendation_system').getOrCreate()\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, DateType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----+----+----+---+----+---------+\n",
      "|_c0| _c1| _c2| _c3|_c4| _c5|      _c6|\n",
      "+---+----+----+----+---+----+---------+\n",
      "|  1|null|1193|null|  5|null|978300760|\n",
      "|  1|null| 661|null|  3|null|978302109|\n",
      "|  1|null| 914|null|  3|null|978301968|\n",
      "|  1|null|3408|null|  4|null|978300275|\n",
      "|  1|null|2355|null|  5|null|978824291|\n",
      "|  1|null|1197|null|  3|null|978302268|\n",
      "|  1|null|1287|null|  5|null|978302039|\n",
      "|  1|null|2804|null|  5|null|978300719|\n",
      "|  1|null| 594|null|  4|null|978302268|\n",
      "|  1|null| 919|null|  4|null|978301368|\n",
      "|  1|null| 595|null|  5|null|978824268|\n",
      "|  1|null| 938|null|  4|null|978301752|\n",
      "|  1|null|2398|null|  4|null|978302281|\n",
      "|  1|null|2918|null|  4|null|978302124|\n",
      "|  1|null|1035|null|  5|null|978301753|\n",
      "|  1|null|2791|null|  4|null|978302188|\n",
      "|  1|null|2687|null|  3|null|978824268|\n",
      "|  1|null|2018|null|  4|null|978301777|\n",
      "|  1|null|3105|null|  5|null|978301713|\n",
      "|  1|null|2797|null|  4|null|978302039|\n",
      "|  1|null|2321|null|  3|null|978302205|\n",
      "|  1|null| 720|null|  3|null|978300760|\n",
      "|  1|null|1270|null|  5|null|978300055|\n",
      "|  1|null| 527|null|  5|null|978824195|\n",
      "|  1|null|2340|null|  3|null|978300103|\n",
      "|  1|null|  48|null|  5|null|978824351|\n",
      "|  1|null|1097|null|  4|null|978301953|\n",
      "|  1|null|1721|null|  4|null|978300055|\n",
      "|  1|null|1545|null|  4|null|978824139|\n",
      "|  1|null| 745|null|  3|null|978824268|\n",
      "|  1|null|2294|null|  4|null|978824291|\n",
      "|  1|null|3186|null|  4|null|978300019|\n",
      "|  1|null|1566|null|  4|null|978824330|\n",
      "|  1|null| 588|null|  4|null|978824268|\n",
      "|  1|null|1907|null|  4|null|978824330|\n",
      "|  1|null| 783|null|  4|null|978824291|\n",
      "|  1|null|1836|null|  5|null|978300172|\n",
      "|  1|null|1022|null|  5|null|978300055|\n",
      "|  1|null|2762|null|  4|null|978302091|\n",
      "|  1|null| 150|null|  5|null|978301777|\n",
      "|  1|null|   1|null|  5|null|978824268|\n",
      "|  1|null|1961|null|  5|null|978301590|\n",
      "|  1|null|1962|null|  4|null|978301753|\n",
      "|  1|null|2692|null|  4|null|978301570|\n",
      "|  1|null| 260|null|  4|null|978300760|\n",
      "|  1|null|1028|null|  5|null|978301777|\n",
      "|  1|null|1029|null|  5|null|978302205|\n",
      "|  1|null|1207|null|  4|null|978300719|\n",
      "|  1|null|2028|null|  5|null|978301619|\n",
      "|  1|null| 531|null|  4|null|978302149|\n",
      "|  1|null|3114|null|  4|null|978302174|\n",
      "|  1|null| 608|null|  4|null|978301398|\n",
      "|  1|null|1246|null|  4|null|978302091|\n",
      "|  2|null|1357|null|  5|null|978298709|\n",
      "|  2|null|3068|null|  4|null|978299000|\n",
      "|  2|null|1537|null|  4|null|978299620|\n",
      "|  2|null| 647|null|  3|null|978299351|\n",
      "|  2|null|2194|null|  4|null|978299297|\n",
      "|  2|null| 648|null|  4|null|978299913|\n",
      "|  2|null|2268|null|  5|null|978299297|\n",
      "|  2|null|2628|null|  3|null|978300051|\n",
      "|  2|null|1103|null|  3|null|978298905|\n",
      "|  2|null|2916|null|  3|null|978299809|\n",
      "|  2|null|3468|null|  5|null|978298542|\n",
      "|  2|null|1210|null|  4|null|978298151|\n",
      "|  2|null|1792|null|  3|null|978299941|\n",
      "|  2|null|1687|null|  3|null|978300174|\n",
      "|  2|null|1213|null|  2|null|978298458|\n",
      "|  2|null|3578|null|  5|null|978298958|\n",
      "|  2|null|2881|null|  3|null|978300002|\n",
      "|  2|null|3030|null|  4|null|978298434|\n",
      "|  2|null|1217|null|  3|null|978298151|\n",
      "|  2|null|3105|null|  4|null|978298673|\n",
      "|  2|null| 434|null|  2|null|978300174|\n",
      "|  2|null|2126|null|  3|null|978300123|\n",
      "|  2|null|3107|null|  2|null|978300002|\n",
      "|  2|null|3108|null|  3|null|978299712|\n",
      "|  2|null|3035|null|  4|null|978298625|\n",
      "|  2|null|1253|null|  3|null|978299120|\n",
      "|  2|null|1610|null|  5|null|978299809|\n",
      "|  2|null| 292|null|  3|null|978300123|\n",
      "|  2|null|2236|null|  5|null|978299220|\n",
      "|  2|null|3071|null|  4|null|978299120|\n",
      "|  2|null| 902|null|  2|null|978298905|\n",
      "|  2|null| 368|null|  4|null|978300002|\n",
      "|  2|null|1259|null|  5|null|978298841|\n",
      "|  2|null|3147|null|  5|null|978298652|\n",
      "|  2|null|1544|null|  4|null|978300174|\n",
      "|  2|null|1293|null|  5|null|978298261|\n",
      "|  2|null|1188|null|  4|null|978299620|\n",
      "|  2|null|3255|null|  4|null|978299321|\n",
      "|  2|null|3256|null|  2|null|978299839|\n",
      "|  2|null|3257|null|  3|null|978300073|\n",
      "|  2|null| 110|null|  5|null|978298625|\n",
      "|  2|null|2278|null|  3|null|978299889|\n",
      "|  2|null|2490|null|  3|null|978299966|\n",
      "|  2|null|1834|null|  4|null|978298813|\n",
      "|  2|null|3471|null|  5|null|978298814|\n",
      "|  2|null| 589|null|  4|null|978299773|\n",
      "|  2|null|1690|null|  3|null|978300051|\n",
      "+---+----+----+----+---+----+---------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"data/mldataset/ratings.dat\", sep=':')\n",
    "df.show(100,truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-------+-----+------+-----+---------+\n",
      "|UserId|Null1|MovieId|Null2|Rating|Null3|TimeStamp|\n",
      "+------+-----+-------+-----+------+-----+---------+\n",
      "|     1| null|   1193| null|     5| null|978300760|\n",
      "|     1| null|    661| null|     3| null|978302109|\n",
      "|     1| null|    914| null|     3| null|978301968|\n",
      "|     1| null|   3408| null|     4| null|978300275|\n",
      "|     1| null|   2355| null|     5| null|978824291|\n",
      "|     1| null|   1197| null|     3| null|978302268|\n",
      "|     1| null|   1287| null|     5| null|978302039|\n",
      "|     1| null|   2804| null|     5| null|978300719|\n",
      "|     1| null|    594| null|     4| null|978302268|\n",
      "|     1| null|    919| null|     4| null|978301368|\n",
      "|     1| null|    595| null|     5| null|978824268|\n",
      "|     1| null|    938| null|     4| null|978301752|\n",
      "|     1| null|   2398| null|     4| null|978302281|\n",
      "|     1| null|   2918| null|     4| null|978302124|\n",
      "|     1| null|   1035| null|     5| null|978301753|\n",
      "|     1| null|   2791| null|     4| null|978302188|\n",
      "|     1| null|   2687| null|     3| null|978824268|\n",
      "|     1| null|   2018| null|     4| null|978301777|\n",
      "|     1| null|   3105| null|     5| null|978301713|\n",
      "|     1| null|   2797| null|     4| null|978302039|\n",
      "+------+-----+-------+-----+------+-----+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's add headers and drop empty columns\n",
    "\n",
    "headerd_schema = StructType([\n",
    "    StructField(\"UserId\", IntegerType()),\n",
    "    StructField(\"Null1\", StringType()),\n",
    "    StructField(\"MovieId\", IntegerType()),\n",
    "    StructField(\"Null2\", StringType()),\n",
    "    StructField(\"Rating\", IntegerType()),\n",
    "    StructField(\"Null3\", StringType()),\n",
    "    StructField(\"TimeStamp\", IntegerType())\n",
    "])\n",
    "\n",
    "df = spark.read.schema(headerd_schema).csv(\"data/mldataset/ratings.dat\", sep=\":\",header=False)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop('Null1', 'Null2', 'Null3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+---------+\n",
      "|UserId|MovieId|Rating|TimeStamp|\n",
      "+------+-------+------+---------+\n",
      "|  6040|    858|     4|956703932|\n",
      "|  6040|   2384|     4|956703954|\n",
      "|  6040|    593|     5|956703954|\n",
      "|  6040|   1961|     4|956703977|\n",
      "|  6040|   2019|     5|956703977|\n",
      "|  6040|    573|     4|956704056|\n",
      "|  6040|   3111|     5|956704056|\n",
      "|  6040|   3505|     4|956704056|\n",
      "|  6040|    213|     5|956704056|\n",
      "|  6040|   1419|     3|956704056|\n",
      "|  6040|   1734|     2|956704081|\n",
      "|  6040|   2503|     5|956704191|\n",
      "|  6040|    919|     5|956704191|\n",
      "|  6040|    912|     5|956704191|\n",
      "|  6040|    527|     5|956704219|\n",
      "|  6040|    318|     4|956704257|\n",
      "|  6040|   1252|     5|956704257|\n",
      "|  6040|    649|     5|956704257|\n",
      "|  6040|   3289|     5|956704305|\n",
      "|  6040|    759|     5|956704448|\n",
      "+------+-------+------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy('TimeStamp').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/mldataset/ratings.dat\", sep=\"::\",header=None, engine='python')\n",
    "df.columns = ['UserId','MovieId','Rating','TimeStamp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users = len(df['UserId'].unique())\n",
    "n_movies = len(df['MovieId'].unique())\n",
    "\n",
    "n_features = 50\n",
    "\n",
    "x = np.array(df[['UserId', 'MovieId']])\n",
    "y = np.array(df['Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (1000209, 1) was passed for an output of shape (None, 2, 50) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1baa4d4d4a7a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Train the model, iterating on the data in batches of 32 samples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 547\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m         steps=steps)\n\u001b[0m\u001b[1;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[1;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2536\u001b[0m           \u001b[0;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2537\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[0;32m-> 2538\u001b[0;31m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[1;32m   2539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2540\u001b[0m       \u001b[0;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[0;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[1;32m    741\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[1;32m    742\u001b[0m                            \u001b[0;34m' was passed for an output of shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m                            \u001b[0;34m' while using as loss `'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'`. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    744\u001b[0m                            \u001b[0;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m                            'as the output.')\n",
      "\u001b[0;31mValueError\u001b[0m: A target array with shape (1000209, 1) was passed for an output of shape (None, 2, 50) while using as loss `mean_squared_error`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Embedding(n_movies*n_users, n_features, input_length=2))\n",
    "model.add(keras.layers.Dropout(0.05))\n",
    "model.add(keras.layers.Dense(units = 150, activation = 'relu'))\n",
    "model.add(keras.layers.Dropout(0.5))\n",
    "model.add(keras.layers.Dense(units = 50, activation = 'softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model, iterating on the data in batches of 32 samples\n",
    "model.fit(x, y, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
